{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNMoakxkWMk657d+zD6p6RX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xKTm4Cl09QV5","executionInfo":{"status":"ok","timestamp":1678030777734,"user_tz":-480,"elapsed":20282,"user":{"displayName":"張可晴","userId":"06130326083553074662"}},"outputId":"9d28e994-02ab-4f8a-d8d6-1e8d7b75a767"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["# for google colab\n","from google.colab import drive\n","# mount your Google Drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","source":["# for google colab\n","# copy all files from \"project1\" directory in Google drive to current directory\n","!cp -r ./gdrive/MyDrive/project1/* ."],"metadata":{"id":"Ds7CJKQD9UrM","executionInfo":{"status":"ok","timestamp":1678030780644,"user_tz":-480,"elapsed":2914,"user":{"displayName":"張可晴","userId":"06130326083553074662"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["import os\n","import numpy as np\n","import pandas as pd\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.model_selection import train_test_split, cross_validate, ParameterGrid\n","from sklearn.metrics import confusion_matrix, classification_report\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.svm import SVC\n","from sklearn.decomposition import LatentDirichletAllocation\n","from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n","from sklearn.model_selection import train_test_split"],"metadata":{"id":"uEthuNNDUV2Q","executionInfo":{"status":"ok","timestamp":1678035239384,"user_tz":-480,"elapsed":5,"user":{"displayName":"張可晴","userId":"06130326083553074662"}}},"execution_count":50,"outputs":[]},{"cell_type":"code","source":["colabPath = '/content/gdrive/MyDrive/project1'\n","# unzip BBCNews.zip\n","zipPath = os.path.join(colabPath, 'BBCNews.zip')\n","!unzip $zipPath "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tr3Cps_Lbgzg","executionInfo":{"status":"ok","timestamp":1678030912648,"user_tz":-480,"elapsed":272,"user":{"displayName":"張可晴","userId":"06130326083553074662"}},"outputId":"d3bd262c-a080-4d70-ddca-b3c7d852e3ed"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Archive:  /content/gdrive/MyDrive/project1/BBCNews.zip\n","  inflating: business/0.txt          \n","  inflating: business/1.txt          \n","  inflating: business/10.txt         \n","  inflating: business/11.txt         \n","  inflating: business/12.txt         \n","  inflating: business/13.txt         \n","  inflating: business/14.txt         \n","  inflating: business/15.txt         \n","  inflating: business/16.txt         \n","  inflating: business/17.txt         \n","  inflating: business/18.txt         \n","  inflating: business/19.txt         \n","  inflating: business/2.txt          \n","  inflating: business/20.txt         \n","  inflating: business/21.txt         \n","  inflating: business/22.txt         \n","  inflating: business/23.txt         \n","  inflating: business/24.txt         \n","  inflating: business/25.txt         \n","  inflating: business/26.txt         \n","  inflating: business/27.txt         \n","  inflating: business/28.txt         \n","  inflating: business/29.txt         \n","  inflating: business/3.txt          \n","  inflating: business/30.txt         \n","  inflating: business/31.txt         \n","  inflating: business/32.txt         \n","  inflating: business/33.txt         \n","  inflating: business/34.txt         \n","  inflating: business/35.txt         \n","  inflating: business/36.txt         \n","  inflating: business/37.txt         \n","  inflating: business/38.txt         \n","  inflating: business/39.txt         \n","  inflating: business/4.txt          \n","  inflating: business/40.txt         \n","  inflating: business/41.txt         \n","  inflating: business/42.txt         \n","  inflating: business/43.txt         \n","  inflating: business/44.txt         \n","  inflating: business/45.txt         \n","  inflating: business/46.txt         \n","  inflating: business/47.txt         \n","  inflating: business/48.txt         \n","  inflating: business/49.txt         \n","  inflating: business/5.txt          \n","  inflating: business/6.txt          \n","  inflating: business/7.txt          \n","  inflating: business/8.txt          \n","  inflating: business/9.txt          \n","  inflating: entertainment-arts/0.txt  \n","  inflating: entertainment-arts/1.txt  \n","  inflating: entertainment-arts/10.txt  \n","  inflating: entertainment-arts/11.txt  \n","  inflating: entertainment-arts/12.txt  \n","  inflating: entertainment-arts/13.txt  \n","  inflating: entertainment-arts/14.txt  \n","  inflating: entertainment-arts/15.txt  \n","  inflating: entertainment-arts/16.txt  \n","  inflating: entertainment-arts/17.txt  \n","  inflating: entertainment-arts/18.txt  \n","  inflating: entertainment-arts/19.txt  \n","  inflating: entertainment-arts/2.txt  \n","  inflating: entertainment-arts/20.txt  \n","  inflating: entertainment-arts/21.txt  \n","  inflating: entertainment-arts/22.txt  \n","  inflating: entertainment-arts/23.txt  \n","  inflating: entertainment-arts/24.txt  \n","  inflating: entertainment-arts/25.txt  \n","  inflating: entertainment-arts/26.txt  \n","  inflating: entertainment-arts/27.txt  \n","  inflating: entertainment-arts/28.txt  \n","  inflating: entertainment-arts/29.txt  \n","  inflating: entertainment-arts/3.txt  \n","  inflating: entertainment-arts/30.txt  \n","  inflating: entertainment-arts/31.txt  \n","  inflating: entertainment-arts/32.txt  \n","  inflating: entertainment-arts/33.txt  \n","  inflating: entertainment-arts/34.txt  \n","  inflating: entertainment-arts/35.txt  \n","  inflating: entertainment-arts/36.txt  \n","  inflating: entertainment-arts/37.txt  \n","  inflating: entertainment-arts/38.txt  \n","  inflating: entertainment-arts/39.txt  \n","  inflating: entertainment-arts/4.txt  \n","  inflating: entertainment-arts/40.txt  \n","  inflating: entertainment-arts/41.txt  \n","  inflating: entertainment-arts/42.txt  \n","  inflating: entertainment-arts/43.txt  \n","  inflating: entertainment-arts/44.txt  \n","  inflating: entertainment-arts/45.txt  \n","  inflating: entertainment-arts/46.txt  \n","  inflating: entertainment-arts/47.txt  \n","  inflating: entertainment-arts/48.txt  \n","  inflating: entertainment-arts/49.txt  \n","  inflating: entertainment-arts/5.txt  \n","  inflating: entertainment-arts/6.txt  \n","  inflating: entertainment-arts/7.txt  \n","  inflating: entertainment-arts/8.txt  \n","  inflating: entertainment-arts/9.txt  \n","  inflating: science-environment/0.txt  \n","  inflating: science-environment/1.txt  \n","  inflating: science-environment/10.txt  \n","  inflating: science-environment/11.txt  \n","  inflating: science-environment/12.txt  \n","  inflating: science-environment/13.txt  \n","  inflating: science-environment/14.txt  \n","  inflating: science-environment/15.txt  \n","  inflating: science-environment/16.txt  \n","  inflating: science-environment/17.txt  \n","  inflating: science-environment/18.txt  \n","  inflating: science-environment/19.txt  \n","  inflating: science-environment/2.txt  \n","  inflating: science-environment/20.txt  \n","  inflating: science-environment/21.txt  \n","  inflating: science-environment/22.txt  \n","  inflating: science-environment/23.txt  \n","  inflating: science-environment/24.txt  \n","  inflating: science-environment/25.txt  \n","  inflating: science-environment/26.txt  \n","  inflating: science-environment/27.txt  \n","  inflating: science-environment/28.txt  \n","  inflating: science-environment/29.txt  \n","  inflating: science-environment/3.txt  \n","  inflating: science-environment/30.txt  \n","  inflating: science-environment/31.txt  \n","  inflating: science-environment/32.txt  \n","  inflating: science-environment/33.txt  \n","  inflating: science-environment/34.txt  \n","  inflating: science-environment/35.txt  \n","  inflating: science-environment/36.txt  \n","  inflating: science-environment/37.txt  \n","  inflating: science-environment/38.txt  \n","  inflating: science-environment/39.txt  \n","  inflating: science-environment/4.txt  \n","  inflating: science-environment/40.txt  \n","  inflating: science-environment/41.txt  \n","  inflating: science-environment/42.txt  \n","  inflating: science-environment/43.txt  \n","  inflating: science-environment/44.txt  \n","  inflating: science-environment/45.txt  \n","  inflating: science-environment/46.txt  \n","  inflating: science-environment/47.txt  \n","  inflating: science-environment/48.txt  \n","  inflating: science-environment/49.txt  \n","  inflating: science-environment/5.txt  \n","  inflating: science-environment/6.txt  \n","  inflating: science-environment/7.txt  \n","  inflating: science-environment/8.txt  \n","  inflating: science-environment/9.txt  \n","  inflating: technology/0.txt        \n","  inflating: technology/1.txt        \n","  inflating: technology/10.txt       \n","  inflating: technology/11.txt       \n","  inflating: technology/12.txt       \n","  inflating: technology/13.txt       \n","  inflating: technology/14.txt       \n","  inflating: technology/15.txt       \n","  inflating: technology/16.txt       \n","  inflating: technology/17.txt       \n","  inflating: technology/18.txt       \n","  inflating: technology/19.txt       \n","  inflating: technology/2.txt        \n","  inflating: technology/20.txt       \n","  inflating: technology/21.txt       \n","  inflating: technology/22.txt       \n","  inflating: technology/23.txt       \n","  inflating: technology/24.txt       \n","  inflating: technology/25.txt       \n","  inflating: technology/26.txt       \n","  inflating: technology/27.txt       \n","  inflating: technology/28.txt       \n","  inflating: technology/29.txt       \n","  inflating: technology/3.txt        \n","  inflating: technology/30.txt       \n","  inflating: technology/31.txt       \n","  inflating: technology/32.txt       \n","  inflating: technology/33.txt       \n","  inflating: technology/34.txt       \n","  inflating: technology/35.txt       \n","  inflating: technology/36.txt       \n","  inflating: technology/37.txt       \n","  inflating: technology/38.txt       \n","  inflating: technology/39.txt       \n","  inflating: technology/4.txt        \n","  inflating: technology/40.txt       \n","  inflating: technology/41.txt       \n","  inflating: technology/42.txt       \n","  inflating: technology/43.txt       \n","  inflating: technology/44.txt       \n","  inflating: technology/45.txt       \n","  inflating: technology/46.txt       \n","  inflating: technology/47.txt       \n","  inflating: technology/48.txt       \n","  inflating: technology/49.txt       \n","  inflating: technology/5.txt        \n","  inflating: technology/6.txt        \n","  inflating: technology/7.txt        \n","  inflating: technology/8.txt        \n","  inflating: technology/9.txt        \n"]}]},{"cell_type":"markdown","source":["# Load Data"],"metadata":{"id":"tviq8dIEPfct"}},{"cell_type":"code","source":["# different categories collected from BBC News\n","cats = ['business', 'technology', 'science-environment', 'entertainment-arts']\n","X = []\n","y = []\n","\n","# Convert a collection of raw documents to a matrix of TF-IDF features.\n","vectorizer = TfidfVectorizer(stop_words='english')\n","# load data from files\n","for idx, cat in enumerate(cats):\n","    cat_dir = f'{ cat }'\n","    for file_name in os.listdir(cat_dir):\n","        with open(f'{ cat_dir }/{ file_name }') as file:\n","            article = file.read()\n","            X.append(article)\n","            y.append(idx)\n","\n","X = vectorizer.fit_transform(X).toarray()\n","y = np.array(y)\n","# used when testing the performance of smaller training dataset\n","X, X_re, y, y_re = train_test_split(X, y, test_size=0.2, random_state=0)"],"metadata":{"id":"ku7kVGp2Pe5v","executionInfo":{"status":"ok","timestamp":1678039870132,"user_tz":-480,"elapsed":267,"user":{"displayName":"張可晴","userId":"06130326083553074662"}}},"execution_count":62,"outputs":[]},{"cell_type":"markdown","source":["# Cross-validation"],"metadata":{"id":"tIQQED9saxzD"}},{"cell_type":"code","source":["def cross_validation(x_train, y_train, k=5):\n","    returnList = list()\n","    folds = list()\n","    # generate numpy array filled with value from 0 to length of x_train for latter use as index\n","    random_idx = np.arange(len(x_train))\n","    seed = 120\n","    np.random.seed(seed)\n","    # shuffle the index\n","    np.random.shuffle(random_idx)\n","    # get the size of each fold\n","    n_split = len(x_train) // k\n","\n","    # separate the index into training part and testing part\n","    keep = 0\n","    for i in range(k):\n","        if i < len(x_train) % k: # used when mode != 0\n","            folds.append(random_idx[keep : keep + n_split + 1])\n","            keep += (n_split + 1)\n","        else:\n","            folds.append(random_idx[keep : keep + n_split])\n","            keep += n_split\n","\n","    for i in range(k):\n","        returnList.append([np.setdiff1d(random_idx, folds[i]), folds[i]])\n","       \n","    return returnList"],"metadata":{"id":"qlycOLBmaxT9","executionInfo":{"status":"ok","timestamp":1678031398612,"user_tz":-480,"elapsed":243,"user":{"displayName":"張可晴","userId":"06130326083553074662"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["folds_data = cross_validation(X, y, k=5)"],"metadata":{"id":"_XjUGxkea2fg","executionInfo":{"status":"ok","timestamp":1678039873902,"user_tz":-480,"elapsed":369,"user":{"displayName":"張可晴","userId":"06130326083553074662"}}},"execution_count":63,"outputs":[]},{"cell_type":"markdown","source":["# kNN"],"metadata":{"id":"rIDRC3ZaaSn2"}},{"cell_type":"code","source":["# loop from 1 to 10 to get the best k\n","for k in range(1, 11):\n","  model = KNeighborsClassifier(n_neighbors=k)\n","  metric1, metric2, metric3, metric4, metric5 = 0, 0, 0, 0, 0\n","\n","  # loop through different specified training and testing data\n","  for i in range(5):\n","    # train the data with kNN classifier\n","    model.fit(X[folds_data[i][0]], y[folds_data[i][0]])\n","    # test data\n","    y_pred = model.predict(X[folds_data[i][1]])\n","\n","    # sum up all folds' metric value\n","    metric1 += accuracy_score(y[folds_data[i][1]], y_pred)\n","    metric2 += precision_score(y[folds_data[i][1]], y_pred, average='weighted')\n","    metric3 += recall_score(y[folds_data[i][1]], y_pred, average='weighted')\n","    metric4 += f1_score(y[folds_data[i][1]], y_pred, average='weighted')\n","    metric5 += roc_auc_score(y[folds_data[i][1]], model.predict_proba(X[folds_data[i][1]]), multi_class='ovr')\n","\n","  # evaluate the model with accuracy, precision, recall, f1-score, aucroc \n","  print(\"k=%d, accuracy=%.2f%%\" % (k, metric1 * 20)) # (100% / 5 folds = 20)\n","  print(\"k=%d, precision=%.2f%%\" % (k, metric2 * 20))\n","  print(\"k=%d, recall=%.2f%%\" % (k, metric3 * 20))\n","  print(\"k=%d, f1_score=%.2f%%\" % (k, metric4 * 20))\n","  print(\"k=%d, AUROC=%.2f%%\" % (k, metric5 * 20))\n","  print('\\n')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fObe5SxpaSLe","executionInfo":{"status":"ok","timestamp":1678039880216,"user_tz":-480,"elapsed":4508,"user":{"displayName":"張可晴","userId":"06130326083553074662"}},"outputId":"5ff3a695-feba-4e4f-f659-46664e16b08e"},"execution_count":64,"outputs":[{"output_type":"stream","name":"stdout","text":["k=1, accuracy=90.62%\n","k=1, precision=91.69%\n","k=1, recall=90.62%\n","k=1, f1_score=90.58%\n","k=1, AUROC=94.07%\n","\n","\n","k=2, accuracy=83.12%\n","k=2, precision=85.16%\n","k=2, recall=83.12%\n","k=2, f1_score=82.92%\n","k=2, AUROC=94.76%\n","\n","\n","k=3, accuracy=85.62%\n","k=3, precision=87.02%\n","k=3, recall=85.62%\n","k=3, f1_score=85.87%\n","k=3, AUROC=95.71%\n","\n","\n","k=4, accuracy=85.62%\n","k=4, precision=87.32%\n","k=4, recall=85.62%\n","k=4, f1_score=85.66%\n","k=4, AUROC=95.87%\n","\n","\n","k=5, accuracy=85.62%\n","k=5, precision=87.47%\n","k=5, recall=85.62%\n","k=5, f1_score=85.80%\n","k=5, AUROC=96.74%\n","\n","\n","k=6, accuracy=83.75%\n","k=6, precision=85.83%\n","k=6, recall=83.75%\n","k=6, f1_score=83.90%\n","k=6, AUROC=96.18%\n","\n","\n","k=7, accuracy=84.38%\n","k=7, precision=86.68%\n","k=7, recall=84.38%\n","k=7, f1_score=84.93%\n","k=7, AUROC=95.91%\n","\n","\n","k=8, accuracy=83.75%\n","k=8, precision=87.06%\n","k=8, recall=83.75%\n","k=8, f1_score=84.37%\n","k=8, AUROC=96.49%\n","\n","\n","k=9, accuracy=84.38%\n","k=9, precision=87.37%\n","k=9, recall=84.38%\n","k=9, f1_score=84.98%\n","k=9, AUROC=96.25%\n","\n","\n","k=10, accuracy=83.75%\n","k=10, precision=87.16%\n","k=10, recall=83.75%\n","k=10, f1_score=84.58%\n","k=10, AUROC=96.16%\n","\n","\n"]}]},{"cell_type":"markdown","source":["# SVM"],"metadata":{"id":"fdjiOJegldQG"}},{"cell_type":"code","source":["# using SVM with different kernel (Gaussian Kernel, Linear Kernel, Polynomial Kernel) to predict Fashion-MNIST\n","# Gaussian Kernel\n","model = SVC(kernel='rbf', decision_function_shape='ovr', probability=True)\n","# Linear Kernel\n","# model = SVC(kernel='linear', decision_function_shape='ovr', probability=True)\n","# Polynomial Kernel\n","# model = SVC(C=10, kernel='poly', gamma=\"auto\", probability=True)\n","metrics = np.zeros(5)\n","\n","# loop through different specified training and testing data\n","for i in range(5):\n","  # train data\n","  model.fit(X[folds_data[i][0]], y[folds_data[i][0]])\n","  # test data\n","  y_pred = model.predict(X[folds_data[i][1]])\n","\n","  # sum up all folds' metric value\n","  metrics[0] += accuracy_score(y[folds_data[i][1]], y_pred)\n","  metrics[1] += precision_score(y[folds_data[i][1]], y_pred, average='weighted')\n","  metrics[2] += recall_score(y[folds_data[i][1]], y_pred, average='weighted')\n","  metrics[3] += f1_score(y[folds_data[i][1]], y_pred, average='weighted')\n","  metrics[4] += roc_auc_score(y[folds_data[i][1]], model.predict_proba(X[folds_data[i][1]]), multi_class='ovr')\n","metrics /= 5\n","\n","# evaluate the model with accuracy, precision, recall, f1-score, aucroc \n","print(\"accuracy=%.2f%%\" % (metrics[0] * 100))\n","print(\"precision=%.2f%%\" % (metrics[1] * 100))\n","print(\"recall=%.2f%%\" % (metrics[2] * 100))\n","print(\"f1_score=%.2f%%\" % (metrics[3] * 100))\n","print(\"AUROC=%.2f%%\" % (metrics[4] * 100))\n","print('\\n')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-43nNt0Llhma","executionInfo":{"status":"ok","timestamp":1678039976547,"user_tz":-480,"elapsed":2828,"user":{"displayName":"張可晴","userId":"06130326083553074662"}},"outputId":"6bf14c5c-0a2a-4574-eb58-0509865ab120"},"execution_count":65,"outputs":[{"output_type":"stream","name":"stdout","text":["accuracy=89.38%\n","precision=90.85%\n","recall=89.38%\n","f1_score=89.44%\n","AUROC=97.77%\n","\n","\n"]}]},{"cell_type":"markdown","source":["# Random forest"],"metadata":{"id":"WVSHovmalnKg"}},{"cell_type":"code","source":["# using random forest with different n_estimators to predict data\n","n_estimator = [100, 300, 1000]\n","\n","for n in n_estimator:\n","  model = RandomForestClassifier(n_estimators=n, max_depth=3, random_state=42)\n","  metrics = np.zeros(5)\n","\n","  # loop through different specified training and testing data\n","  for i in range(5):\n","    # training the random forest classifier\n","    model.fit(X[folds_data[i][0]], y[folds_data[i][0]])\n","    # test data\n","    y_pred = model.predict(X[folds_data[i][1]])\n","\n","    # sum up all folds' metric value\n","    metrics[0] += accuracy_score(y[folds_data[i][1]], y_pred)\n","    metrics[1] += precision_score(y[folds_data[i][1]], y_pred, average='weighted')\n","    metrics[2] += recall_score(y[folds_data[i][1]], y_pred, average='weighted')\n","    metrics[3] += f1_score(y[folds_data[i][1]], y_pred, average='weighted')\n","    metrics[4] += roc_auc_score(y[folds_data[i][1]], model.predict_proba(X[folds_data[i][1]]), multi_class='ovr')\n","  metrics /= 5\n","\n","# evaluate the model with accuracy, precision, recall, f1-score, aucroc\n","  print(\"n_estimator: %d\" % (n))\n","  print(\"accuracy=%.2f%%\" % (metrics[0] * 100))\n","  print(\"precision=%.2f%%\" % (metrics[1] * 100))\n","  print(\"recall=%.2f%%\" % (metrics[2] * 100))\n","  print(\"f1_score=%.2f%%\" % (metrics[3] * 100))\n","  print(\"AUROC=%.2f%%\" % (metrics[4] * 100))\n","  print('\\n')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ah5FHj3Lmrzp","executionInfo":{"status":"ok","timestamp":1678040005418,"user_tz":-480,"elapsed":15743,"user":{"displayName":"張可晴","userId":"06130326083553074662"}},"outputId":"aa8390ff-a230-4642-b5c7-57051ac69069"},"execution_count":66,"outputs":[{"output_type":"stream","name":"stdout","text":["n_estimator: 100\n","accuracy=71.25%\n","precision=83.76%\n","recall=71.25%\n","f1_score=71.99%\n","AUROC=95.75%\n","\n","\n","n_estimator: 300\n","accuracy=75.62%\n","precision=85.14%\n","recall=75.62%\n","f1_score=76.41%\n","AUROC=96.82%\n","\n","\n","n_estimator: 1000\n","accuracy=76.88%\n","precision=85.89%\n","recall=76.88%\n","f1_score=77.66%\n","AUROC=96.94%\n","\n","\n"]}]}]}